{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cxCklIOc6SBp"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os, os.path\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Input, Flatten, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.activations import relu, tanh\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-Dv7mPrXAoCC"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "batch_size = 10\n",
    "epochs = 1000\n",
    "coef_reg = 0 # Coefficient for L2 regularizer of weights\n",
    "coef_bias_reg = 0 # Coefficient for L2 regularizer of biases\n",
    "act = 'relu' # Choice of activation functions (either relu or tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KDJvdK5p5fEv"
   },
   "outputs": [],
   "source": [
    "def createDataset(img_folder, label_path,scale_percent=70):\n",
    "# This function create dataset from a folder of images and a label file. \n",
    "# scale_percent is how much you want to scale the images down\n",
    "# The outputs are a numpy array of images and a numpy array of locations of phones\n",
    "    images = []\n",
    "    labels = []\n",
    "    f = open(label_path)\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if(line.strip() != \"\"):\n",
    "            img, x, y = line.split(\" \")\n",
    "            if(os.path.exists(os.path.join(img_folder,img))):\n",
    "                img_ = cv2.imread(os.path.join(img_folder,img))\n",
    "                width = int(img_.shape[1] * scale_percent / 100)\n",
    "                height = int(img_.shape[0] * scale_percent / 100)\n",
    "                dim = (width, height)\n",
    "                images.append(cv2.resize(img_, dim, interpolation = cv2.INTER_AREA))\n",
    "                labels.append([float(x),float(y)])\n",
    "    return np.asarray(images).astype(\"float32\"), np.asarray(labels).astype(\"float32\") #tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\n",
    "\n",
    "def getAccuracy(model, x, y):\n",
    "# This function computes the accuracy of a model with respect to input x and the ground-truth label y\n",
    "  y_pred = model.predict(x)\n",
    "  diff = np.abs(y_pred - y)\n",
    "  correct = 0\n",
    "  for pair in diff:\n",
    "    if(pair[0] <= 0.05 and pair[1] <= 0.05):\n",
    "      correct += 1\n",
    "  return correct / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vSszcKHY8X_b"
   },
   "outputs": [],
   "source": [
    "x, y = createDataset(\"find_phone_data\", \"find_phone_data/labels.txt\") # Build a training dataset\n",
    "x = x/255  # Normalize the dataset\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2, shuffle=True) # Split the dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exxoAgnzDTob",
    "outputId": "f04b738f-3059-4aa4-b935-1438d09bc70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 228, 343, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 228, 343, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 228, 343, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 114, 172, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 114, 172, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 114, 172, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 57, 86, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 57, 86, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 57, 86, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 57, 86, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 29, 43, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 29, 43, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 29, 43, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 29, 43, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 22, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 15, 22, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 15, 22, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 15, 22, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 15, 22, 512)      2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 15, 22, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 11, 512)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 45056)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              184553472 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,368,898\n",
      "Trainable params: 201,367,874\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 13:05:27.737809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-30 13:05:28.300438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6437 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Build a machine learning model for phone detection based on VGG-16\n",
    "\n",
    "input = Input((x.shape[1], x.shape[2], x.shape[3]))\n",
    "# 1st Conv Block\n",
    "\n",
    "conv1 = Conv2D (filters =64, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(input)\n",
    "conv2 = Conv2D (filters =64, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv1)\n",
    "max1 = MaxPool2D(pool_size =2, strides =2, padding ='same')(conv2)\n",
    "# 2nd Conv Block\n",
    "\n",
    "conv3 = Conv2D (filters =128, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(max1)\n",
    "conv4 = Conv2D (filters =128, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv3)\n",
    "max2 = MaxPool2D(pool_size =2, strides =2, padding ='same')(conv4)\n",
    "\n",
    "# 3rd Conv block\n",
    "\n",
    "conv5 = Conv2D (filters =256, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(max2)\n",
    "conv6 = Conv2D (filters =256, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv5)\n",
    "conv7 = Conv2D (filters =256, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv6)\n",
    "max3 = MaxPool2D(pool_size =2, strides =2, padding ='same')(conv7)\n",
    "# 4th Conv block\n",
    "\n",
    "conv8 = Conv2D (filters =512, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(max3)\n",
    "conv9 = Conv2D (filters =512, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv8)\n",
    "conv10 = Conv2D (filters =512, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv9)\n",
    "max4 = MaxPool2D(pool_size =2, strides =2, padding ='same')(conv10)\n",
    "\n",
    "# 5th Conv block\n",
    "\n",
    "conv11 = Conv2D (filters =512, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(max4)\n",
    "conv12 = Conv2D (filters =512, kernel_size =3, padding ='same', activation=act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv11)\n",
    "conv13 = Conv2D (filters =512, kernel_size =3, padding ='same', kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(conv12)\n",
    "batch2 = BatchNormalization()(conv13)\n",
    "if(act == 'relu'):\n",
    "  act1 = relu(batch2)\n",
    "elif(act == 'tanh'):\n",
    "  act1 = tanh(batch2)\n",
    "max5 = MaxPool2D(pool_size =2, strides =2, padding ='same')(act1)\n",
    "\n",
    "# Fully connected layers\n",
    "\n",
    "flat = Flatten()(max5)\n",
    "dense1 = Dense(units = 4096, activation =act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(flat)\n",
    "drop1 = Dropout(0.8)(dense1)\n",
    "dense2 = Dense(units = 512, activation =act, kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(drop1)\n",
    "output = Dense(units = 2, activation ='sigmoid', kernel_regularizer=L2(coef_reg), bias_regularizer=L2(coef_bias_reg))(dense2)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "model = Model (inputs=input, outputs =output)\n",
    "model.compile(optimizer=optimizer, loss=tf.losses.MeanSquaredError(),metrics=['mae', 'mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZEcfJl8-geK",
    "outputId": "87a38b4b-f47d-4353-9f42-ba849583df3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 13:05:32.352175: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8302\n",
      "2022-08-30 13:05:32.710047: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-08-30 13:05:33.282270: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-30 13:05:33.316305: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-30 13:05:33.487733: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-30 13:05:33.504403: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/11 [==========================>...] - ETA: 0s - loss: 0.0578 - mae: 0.2075 - mse: 0.0578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 13:05:36.756088: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-30 13:05:36.779318: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 9s 389ms/step - loss: 0.0573 - mae: 0.2065 - mse: 0.0573 - val_loss: 0.0517 - val_mae: 0.1975 - val_mse: 0.0517 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.0559 - mae: 0.2057 - mse: 0.0559 - val_loss: 0.0518 - val_mae: 0.1976 - val_mse: 0.0518 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.0553 - mae: 0.2060 - mse: 0.0553 - val_loss: 0.0519 - val_mae: 0.1975 - val_mse: 0.0519 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0506 - mae: 0.1968 - mse: 0.0506 - val_loss: 0.0502 - val_mae: 0.1943 - val_mse: 0.0502 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0399 - mae: 0.1561 - mse: 0.0399 - val_loss: 0.0504 - val_mae: 0.1944 - val_mse: 0.0504 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0265 - mae: 0.1276 - mse: 0.0265 - val_loss: 0.0474 - val_mae: 0.1883 - val_mse: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0188 - mae: 0.1060 - mse: 0.0188 - val_loss: 0.0486 - val_mae: 0.1908 - val_mse: 0.0486 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0135 - mae: 0.0883 - mse: 0.0135 - val_loss: 0.0474 - val_mae: 0.1886 - val_mse: 0.0474 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0076 - mae: 0.0683 - mse: 0.0076 - val_loss: 0.0457 - val_mae: 0.1853 - val_mse: 0.0457 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0085 - mae: 0.0730 - mse: 0.0085 - val_loss: 0.0443 - val_mae: 0.1828 - val_mse: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0087 - mae: 0.0750 - mse: 0.0087 - val_loss: 0.0458 - val_mae: 0.1856 - val_mse: 0.0458 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0054 - mae: 0.0591 - mse: 0.0054 - val_loss: 0.0468 - val_mae: 0.1878 - val_mse: 0.0468 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0046 - mae: 0.0555 - mse: 0.0046 - val_loss: 0.0467 - val_mae: 0.1874 - val_mse: 0.0467 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0043 - mae: 0.0523 - mse: 0.0043 - val_loss: 0.0443 - val_mae: 0.1826 - val_mse: 0.0443 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0035 - mae: 0.0454 - mse: 0.0035 - val_loss: 0.0447 - val_mae: 0.1834 - val_mse: 0.0447 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.0025 - mae: 0.0404 - mse: 0.0025 - val_loss: 0.0448 - val_mae: 0.1835 - val_mse: 0.0448 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0025 - mae: 0.0399 - mse: 0.0025 - val_loss: 0.0449 - val_mae: 0.1839 - val_mse: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0018 - mae: 0.0328 - mse: 0.0018 - val_loss: 0.0454 - val_mae: 0.1851 - val_mse: 0.0454 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.0020 - mae: 0.0352 - mse: 0.0020 - val_loss: 0.0449 - val_mae: 0.1843 - val_mse: 0.0449 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0027 - mae: 0.0410 - mse: 0.0027 - val_loss: 0.0420 - val_mae: 0.1782 - val_mse: 0.0420 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0021 - mae: 0.0367 - mse: 0.0021 - val_loss: 0.0427 - val_mae: 0.1795 - val_mse: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0020 - mae: 0.0338 - mse: 0.0020 - val_loss: 0.0423 - val_mae: 0.1784 - val_mse: 0.0423 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0021 - mae: 0.0365 - mse: 0.0021 - val_loss: 0.0437 - val_mae: 0.1815 - val_mse: 0.0437 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.0018 - mae: 0.0331 - mse: 0.0018 - val_loss: 0.0427 - val_mae: 0.1795 - val_mse: 0.0427 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0016 - mae: 0.0321 - mse: 0.0016 - val_loss: 0.0392 - val_mae: 0.1720 - val_mse: 0.0392 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0017 - mae: 0.0341 - mse: 0.0017 - val_loss: 0.0404 - val_mae: 0.1745 - val_mse: 0.0404 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0015 - mae: 0.0295 - mse: 0.0015 - val_loss: 0.0398 - val_mae: 0.1733 - val_mse: 0.0398 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0011 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0372 - val_mae: 0.1678 - val_mse: 0.0372 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0016 - mae: 0.0318 - mse: 0.0016 - val_loss: 0.0388 - val_mae: 0.1713 - val_mse: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0019 - mae: 0.0354 - mse: 0.0019 - val_loss: 0.0391 - val_mae: 0.1719 - val_mse: 0.0391 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0017 - mae: 0.0336 - mse: 0.0017 - val_loss: 0.0370 - val_mae: 0.1673 - val_mse: 0.0370 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0015 - mae: 0.0298 - mse: 0.0015 - val_loss: 0.0376 - val_mae: 0.1688 - val_mse: 0.0376 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0014 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0359 - val_mae: 0.1647 - val_mse: 0.0359 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0017 - mae: 0.0330 - mse: 0.0017 - val_loss: 0.0319 - val_mae: 0.1553 - val_mse: 0.0319 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0013 - mae: 0.0287 - mse: 0.0013 - val_loss: 0.0332 - val_mae: 0.1586 - val_mse: 0.0332 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.0012 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0292 - val_mae: 0.1488 - val_mse: 0.0292 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.0013 - mae: 0.0300 - mse: 0.0013 - val_loss: 0.0282 - val_mae: 0.1464 - val_mse: 0.0282 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0014 - mae: 0.0304 - mse: 0.0014 - val_loss: 0.0289 - val_mae: 0.1477 - val_mse: 0.0289 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0014 - mae: 0.0282 - mse: 0.0014 - val_loss: 0.0308 - val_mae: 0.1526 - val_mse: 0.0308 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.0012 - mae: 0.0270 - mse: 0.0012 - val_loss: 0.0273 - val_mae: 0.1437 - val_mse: 0.0273 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0014 - mae: 0.0292 - mse: 0.0014 - val_loss: 0.0290 - val_mae: 0.1480 - val_mse: 0.0290 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.0016 - mae: 0.0310 - mse: 0.0016 - val_loss: 0.0271 - val_mae: 0.1430 - val_mse: 0.0271 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.0014 - mae: 0.0289 - mse: 0.0014 - val_loss: 0.0251 - val_mae: 0.1374 - val_mse: 0.0251 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.0011 - mae: 0.0262 - mse: 0.0011 - val_loss: 0.0211 - val_mae: 0.1258 - val_mse: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 0.0011 - mae: 0.0258 - mse: 0.0011 - val_loss: 0.0198 - val_mae: 0.1220 - val_mse: 0.0198 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.0010 - mae: 0.0253 - mse: 0.0010 - val_loss: 0.0169 - val_mae: 0.1119 - val_mse: 0.0169 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.0016 - mae: 0.0323 - mse: 0.0016 - val_loss: 0.0156 - val_mae: 0.1079 - val_mse: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0017 - mae: 0.0326 - mse: 0.0017 - val_loss: 0.0145 - val_mae: 0.1030 - val_mse: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0015 - mae: 0.0311 - mse: 0.0015 - val_loss: 0.0123 - val_mae: 0.0955 - val_mse: 0.0123 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0023 - mae: 0.0378 - mse: 0.0023 - val_loss: 0.0143 - val_mae: 0.1031 - val_mse: 0.0143 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.0013 - mae: 0.0292 - mse: 0.0013 - val_loss: 0.0140 - val_mae: 0.1018 - val_mse: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.0014 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0110 - val_mae: 0.0894 - val_mse: 0.0110 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 3s 275ms/step - loss: 0.0011 - mae: 0.0267 - mse: 0.0011 - val_loss: 0.0112 - val_mae: 0.0907 - val_mse: 0.0112 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0014 - mae: 0.0296 - mse: 0.0014 - val_loss: 0.0104 - val_mae: 0.0869 - val_mse: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.0011 - mae: 0.0272 - mse: 0.0011 - val_loss: 0.0101 - val_mae: 0.0850 - val_mse: 0.0101 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 9.8250e-04 - mae: 0.0246 - mse: 9.8250e-04 - val_loss: 0.0113 - val_mae: 0.0920 - val_mse: 0.0113 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0014 - mae: 0.0294 - mse: 0.0014 - val_loss: 0.0093 - val_mae: 0.0819 - val_mse: 0.0093 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0010 - mae: 0.0244 - mse: 0.0010 - val_loss: 0.0067 - val_mae: 0.0674 - val_mse: 0.0067 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0011 - mae: 0.0247 - mse: 0.0011 - val_loss: 0.0056 - val_mae: 0.0600 - val_mse: 0.0056 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 9.6582e-04 - mae: 0.0241 - mse: 9.6582e-04 - val_loss: 0.0070 - val_mae: 0.0700 - val_mse: 0.0070 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 9.7436e-04 - mae: 0.0239 - mse: 9.7436e-04 - val_loss: 0.0061 - val_mae: 0.0662 - val_mse: 0.0061 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.0010 - mae: 0.0238 - mse: 0.0010 - val_loss: 0.0050 - val_mae: 0.0579 - val_mse: 0.0050 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 9.2124e-04 - mae: 0.0240 - mse: 9.2124e-04 - val_loss: 0.0042 - val_mae: 0.0515 - val_mse: 0.0042 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 9.0602e-04 - mae: 0.0236 - mse: 9.0602e-04 - val_loss: 0.0045 - val_mae: 0.0554 - val_mse: 0.0045 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.0010 - mae: 0.0250 - mse: 0.0010 - val_loss: 0.0043 - val_mae: 0.0499 - val_mse: 0.0043 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 7.4254e-04 - mae: 0.0215 - mse: 7.4254e-04 - val_loss: 0.0037 - val_mae: 0.0482 - val_mse: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 7.0091e-04 - mae: 0.0209 - mse: 7.0091e-04 - val_loss: 0.0030 - val_mae: 0.0423 - val_mse: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 3s 284ms/step - loss: 7.8945e-04 - mae: 0.0219 - mse: 7.8945e-04 - val_loss: 0.0036 - val_mae: 0.0472 - val_mse: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 3s 281ms/step - loss: 8.7746e-04 - mae: 0.0235 - mse: 8.7746e-04 - val_loss: 0.0038 - val_mae: 0.0458 - val_mse: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 9.2959e-04 - mae: 0.0242 - mse: 9.2959e-04 - val_loss: 0.0028 - val_mae: 0.0367 - val_mse: 0.0028 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 9.8147e-04 - mae: 0.0246 - mse: 9.8147e-04 - val_loss: 0.0025 - val_mae: 0.0353 - val_mse: 0.0025 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.0011 - mae: 0.0254 - mse: 0.0011 - val_loss: 0.0021 - val_mae: 0.0284 - val_mse: 0.0021 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 7.0352e-04 - mae: 0.0204 - mse: 7.0352e-04 - val_loss: 0.0025 - val_mae: 0.0371 - val_mse: 0.0025 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0012 - mae: 0.0269 - mse: 0.0012 - val_loss: 0.0025 - val_mae: 0.0365 - val_mse: 0.0025 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 9.0859e-04 - mae: 0.0242 - mse: 9.0859e-04 - val_loss: 0.0031 - val_mae: 0.0436 - val_mse: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 7.9309e-04 - mae: 0.0219 - mse: 7.9309e-04 - val_loss: 0.0026 - val_mae: 0.0364 - val_mse: 0.0026 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 7.8768e-04 - mae: 0.0219 - mse: 7.8768e-04 - val_loss: 0.0021 - val_mae: 0.0318 - val_mse: 0.0021 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 8.6343e-04 - mae: 0.0233 - mse: 8.6343e-04 - val_loss: 0.0017 - val_mae: 0.0252 - val_mse: 0.0017 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0013 - mae: 0.0273 - mse: 0.0013 - val_loss: 0.0016 - val_mae: 0.0236 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0012 - mae: 0.0275 - mse: 0.0012 - val_loss: 0.0015 - val_mae: 0.0263 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 8.4277e-04 - mae: 0.0232 - mse: 8.4277e-04 - val_loss: 0.0013 - val_mae: 0.0233 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 8.6609e-04 - mae: 0.0239 - mse: 8.6609e-04 - val_loss: 0.0016 - val_mae: 0.0251 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 8.3420e-04 - mae: 0.0222 - mse: 8.3420e-04 - val_loss: 0.0018 - val_mae: 0.0294 - val_mse: 0.0018 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 8.5626e-04 - mae: 0.0239 - mse: 8.5626e-04 - val_loss: 0.0015 - val_mae: 0.0267 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 7.6302e-04 - mae: 0.0220 - mse: 7.6302e-04 - val_loss: 0.0015 - val_mae: 0.0254 - val_mse: 0.0015 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 9.8220e-04 - mae: 0.0251 - mse: 9.8220e-04 - val_loss: 0.0016 - val_mae: 0.0248 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 7.5407e-04 - mae: 0.0216 - mse: 7.5407e-04 - val_loss: 0.0016 - val_mae: 0.0257 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0010 - mae: 0.0245 - mse: 0.0010 - val_loss: 0.0013 - val_mae: 0.0216 - val_mse: 0.0013 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 9.3474e-04 - mae: 0.0237 - mse: 9.3474e-04 - val_loss: 0.0019 - val_mae: 0.0289 - val_mse: 0.0019 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 9.2253e-04 - mae: 0.0240 - mse: 9.2253e-04 - val_loss: 0.0016 - val_mae: 0.0239 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.0787e-04 - mae: 0.0197 - mse: 6.0787e-04 - val_loss: 0.0016 - val_mae: 0.0222 - val_mse: 0.0016 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 6.6020e-04 - mae: 0.0197 - mse: 6.6020e-04 - val_loss: 0.0015 - val_mae: 0.0205 - val_mse: 0.0015 - lr: 2.0000e-05\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.7124e-04 - mae: 0.0202 - mse: 6.7124e-04 - val_loss: 0.0014 - val_mae: 0.0201 - val_mse: 0.0014 - lr: 2.0000e-05\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 6.5534e-04 - mae: 0.0199 - mse: 6.5534e-04 - val_loss: 0.0014 - val_mae: 0.0199 - val_mse: 0.0014 - lr: 2.0000e-05\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 6.3324e-04 - mae: 0.0188 - mse: 6.3324e-04 - val_loss: 0.0015 - val_mae: 0.0209 - val_mse: 0.0015 - lr: 2.0000e-05\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 8.6677e-04 - mae: 0.0223 - mse: 8.6677e-04 - val_loss: 0.0019 - val_mae: 0.0241 - val_mse: 0.0019 - lr: 2.0000e-05\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 5.6466e-04 - mae: 0.0185 - mse: 5.6466e-04 - val_loss: 0.0015 - val_mae: 0.0206 - val_mse: 0.0015 - lr: 2.0000e-05\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 8.6122e-04 - mae: 0.0224 - mse: 8.6122e-04 - val_loss: 0.0015 - val_mae: 0.0202 - val_mse: 0.0015 - lr: 2.0000e-05\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 5.7667e-04 - mae: 0.0187 - mse: 5.7667e-04 - val_loss: 0.0014 - val_mae: 0.0197 - val_mse: 0.0014 - lr: 2.0000e-05\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 6.5994e-04 - mae: 0.0200 - mse: 6.5994e-04 - val_loss: 0.0014 - val_mae: 0.0205 - val_mse: 0.0014 - lr: 2.0000e-05\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 6.7615e-04 - mae: 0.0202 - mse: 6.7615e-04 - val_loss: 0.0012 - val_mae: 0.0199 - val_mse: 0.0012 - lr: 2.0000e-05\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 5.6805e-04 - mae: 0.0186 - mse: 5.6805e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 6.4832e-04 - mae: 0.0204 - mse: 6.4832e-04 - val_loss: 0.0011 - val_mae: 0.0192 - val_mse: 0.0011 - lr: 4.0000e-06\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 6.8259e-04 - mae: 0.0210 - mse: 6.8259e-04 - val_loss: 0.0012 - val_mae: 0.0197 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 5.7788e-04 - mae: 0.0185 - mse: 5.7788e-04 - val_loss: 0.0012 - val_mae: 0.0198 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 6.6869e-04 - mae: 0.0196 - mse: 6.6869e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 5.6241e-04 - mae: 0.0185 - mse: 5.6241e-04 - val_loss: 0.0011 - val_mae: 0.0189 - val_mse: 0.0011 - lr: 4.0000e-06\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 5.6575e-04 - mae: 0.0190 - mse: 5.6575e-04 - val_loss: 0.0011 - val_mae: 0.0192 - val_mse: 0.0011 - lr: 4.0000e-06\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 6.2286e-04 - mae: 0.0189 - mse: 6.2286e-04 - val_loss: 0.0012 - val_mae: 0.0192 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 6.3866e-04 - mae: 0.0197 - mse: 6.3866e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.1951e-04 - mae: 0.0187 - mse: 6.1951e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 5.9390e-04 - mae: 0.0187 - mse: 5.9390e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.5144e-04 - mae: 0.0198 - mse: 6.5144e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 4.0000e-06\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 5.8103e-04 - mae: 0.0193 - mse: 5.8103e-04 - val_loss: 0.0012 - val_mae: 0.0192 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 115/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.5823e-04 - mae: 0.0199 - mse: 6.5823e-04 - val_loss: 0.0012 - val_mae: 0.0192 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.3232e-04 - mae: 0.0193 - mse: 6.3232e-04 - val_loss: 0.0011 - val_mae: 0.0192 - val_mse: 0.0011 - lr: 1.0000e-06\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 5.7259e-04 - mae: 0.0185 - mse: 5.7259e-04 - val_loss: 0.0012 - val_mae: 0.0192 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 6.2425e-04 - mae: 0.0191 - mse: 6.2425e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 5.8787e-04 - mae: 0.0187 - mse: 5.8787e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.1442e-04 - mae: 0.0202 - mse: 6.1442e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 5.4936e-04 - mae: 0.0185 - mse: 5.4936e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 6.5727e-04 - mae: 0.0205 - mse: 6.5727e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 6.0492e-04 - mae: 0.0193 - mse: 6.0492e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 5.6526e-04 - mae: 0.0187 - mse: 5.6526e-04 - val_loss: 0.0012 - val_mae: 0.0193 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 5.7474e-04 - mae: 0.0188 - mse: 5.7474e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 5.7033e-04 - mae: 0.0192 - mse: 5.7033e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 1.0000e-06\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 5.5479e-04 - mae: 0.0186 - mse: 5.5479e-04 - val_loss: 0.0012 - val_mae: 0.0194 - val_mse: 0.0012 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=0.000001) # Reduce the learning rate when it is plateau\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=20) # Early stop the training when there is no improvement\n",
    "hist = model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_val, y_val), callbacks=[earlystop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YSXTrckAl4ex"
   },
   "outputs": [],
   "source": [
    "model.save(\"phone_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nGcx-F0laAxo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.title(\"Loss (MSE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EY4N5rlImKLh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca60cffac0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['mae'])\n",
    "plt.plot(hist.history['val_mae'])\n",
    "plt.legend([\"Training\", \"Validation\"])\n",
    "plt.title(\"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "acdD738_BsnV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Training accuracy: 1.0\n",
      "Val accuracy: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "training_acc = getAccuracy(model, x_train, y_train)\n",
    "val_acc = getAccuracy(model, x_val, y_val)\n",
    "print(f\"Training accuracy: {training_acc}\\nVal accuracy: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "jlYyCfzEaZhk"
   },
   "outputs": [],
   "source": [
    "def findPhone(img_path, model, scale_percent=70):\n",
    "# This function is to locate a phone in the given image by a model\n",
    "    img_ = cv2.imread(img_path)\n",
    "    width = int(img_.shape[1] * scale_percent / 100)\n",
    "    height = int(img_.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    img_ = cv2.resize(img_, dim, interpolation = cv2.INTER_AREA)/255\n",
    "    pred = model.predict(tf.expand_dims(img_, axis=0))\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7612411, 0.4388348], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
